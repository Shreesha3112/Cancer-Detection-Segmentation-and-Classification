{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cancer dataset preparation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBFZEA9vT0Hq"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAedTN1CT278"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z_tsfS3T5Nu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrfmL7ZyKcOG"
      },
      "source": [
        "## Data locations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxurcqeoT68G"
      },
      "source": [
        "### Mount google drive - provide google drive access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hu97BGlT7hZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347c94a5-8a88-4f9b-baa8-a5a124996d4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uIt3yXlUDW4"
      },
      "source": [
        "### Set paths correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtUSjoD087-2"
      },
      "source": [
        "#Train\n",
        "\n",
        "ORIGINAL_CANCER_TRAIN_PATH = '/gdrive/My Drive/projects/cancer_detection/train/original/cancer'\n",
        "ORIGINAL_NON_CANCER_TRAIN_PATH = '/gdrive/My Drive/projects/cancer_detection/train/original/non cancer'\n",
        "AUGMENTED_TRAIN_PATH = '/gdrive/My Drive/projects/cancer_detection/train/augmented/images'\n",
        "MASK_TRAIN_PATH = '/gdrive/My Drive/projects/cancer_detection/train/augmented/labels/'\n",
        "\n",
        "#Test\n",
        "ORIGINAL_TEST_PATH = \"/gdrive/My Drive/projects/cancer_detection/test/images\"\n",
        "MASK_TEST_PATH = \"/gdrive/My Drive/projects/cancer_detection/test/labels\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1wDSn-cHMyf"
      },
      "source": [
        "## **Create dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqH18c1akAow"
      },
      "source": [
        "### Augmentation of Train data\n",
        "\n",
        "Augment original cancer images and create augmented train images, which will be used for training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-tQOE-YzzDW"
      },
      "source": [
        "def delete_folder_contents(folder):\n",
        "  \n",
        "  for filename in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOv2p4imVTLD"
      },
      "source": [
        "770 images of cancer . Below are augmentation applied:\n",
        "\n",
        "* image rotation\n",
        "* Horizontal flip\n",
        "* Vertical flip\n",
        "* Shift image height\n",
        "* Shift image width\n",
        "* Zoom image\n",
        "* shear image - slant image by some angle clockwise or anti clockwise\n",
        "\n",
        "330 images of non cancer.Beow are augmentation applied\n",
        "\n",
        "* image rotation\n",
        "* Horizontal flip\n",
        "* Vertical flip\n",
        "\n",
        "The imbalance in data is required to avoid bias towards non cancer, during segmentation\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "\n",
        "Data augmentation example\n",
        "https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7SVTQWHkaOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e418e295-f41f-4dfe-c1ad-74c90045a4aa"
      },
      "source": [
        "# ImageDataGenerator - Used for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    #random rotation of image by 20 degrees\n",
        "    rotation_range=20,\n",
        "    height_shift_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    #fill the newly created pixels based on nearest neighbour basis\n",
        "    fill_mode='nearest'\n",
        ") \n",
        "\n",
        "#Clean the folder before adding fresh images\n",
        "delete_folder_contents(AUGMENTED_TRAIN_PATH)\n",
        "\n",
        "#Load data from ORIGINAL_CANCER_TRAIN_PATH and save in AUGMENTED_TRAIN_PATH\n",
        "cancer_data_generator_1 = datagen.flow_from_directory(\n",
        "        #Original cancer image folder\n",
        "        ORIGINAL_CANCER_TRAIN_PATH,\n",
        "        #target size\n",
        "        target_size = (720 , 720),\n",
        "        #Save the augmented images in this folder\n",
        "        save_to_dir= AUGMENTED_TRAIN_PATH,\n",
        "        #prefix for image file name - cancer_img01.png for example\n",
        "        save_prefix='cancer',\n",
        "        #Number of images in a batch\n",
        "        batch_size=1)\n",
        "\n",
        "#Load data from ORIGINAL_CANCER_TRAIN_PATH and save in AUGMENTED_TRAIN_PATH\n",
        "cancer_data_generator_2 = datagen.flow_from_directory(\n",
        "        #Original cancer image folder\n",
        "        ORIGINAL_CANCER_TRAIN_PATH,\n",
        "        #target size\n",
        "        target_size = (720 , 720),\n",
        "        #Save the augmented images in this folder\n",
        "        save_to_dir= AUGMENTED_TRAIN_PATH,\n",
        "        #prefix for image file name - cancer_img01.png for example\n",
        "        save_prefix='non_cancer',\n",
        "        #Number of images in a batch\n",
        "        batch_size=1)\n",
        "\n",
        "#For non cancer\n",
        "non_cancer_data_generator_1 = ImageDataGenerator(rotation_range=20,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.2,\n",
        ").flow_from_directory(\n",
        "        ORIGINAL_NON_CANCER_TRAIN_PATH,\n",
        "        target_size = (720 , 720),\n",
        "        save_to_dir= AUGMENTED_TRAIN_PATH,\n",
        "        save_prefix='non_cancer',\n",
        "        batch_size=1)\n",
        "\n",
        "non_cancer_data_generator_2 = ImageDataGenerator(rotation_range=20,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.2,\n",
        ").flow_from_directory(\n",
        "        ORIGINAL_NON_CANCER_TRAIN_PATH,\n",
        "        target_size = (720 , 720),\n",
        "        save_to_dir= AUGMENTED_TRAIN_PATH,\n",
        "        save_prefix='cancer',\n",
        "        batch_size=1)\n",
        "\n",
        "#Genrate 770 cancer images\n",
        "for i in range(770):\n",
        "    next(cancer_data_generator_1)\n",
        "\n",
        "#Genrate 330 non cancer images\n",
        "for i in range(330):\n",
        "  next(non_cancer_data_generator_1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 125 images belonging to 1 classes.\n",
            "Found 125 images belonging to 1 classes.\n",
            "Found 23 images belonging to 1 classes.\n",
            "Found 23 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'for i in range(220):\\n  next(non_cancer_data_generator_2)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcn3W7rImSqV"
      },
      "source": [
        "### Load dataset\n",
        "\n",
        "Lets use mask image name is same as train image name. Filenames of the images are stored for this purpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqw9nVEdU49S"
      },
      "source": [
        "def create_dataset(path):\n",
        "\n",
        "  #Image dataset\n",
        "  dataset = []\n",
        "  #Corresponding image file names\n",
        "  filenames = []\n",
        "    \n",
        "  for img in os.listdir(path):  # iterate over each image\n",
        "            try:\n",
        "                filenames.append(img)\n",
        "                #read image\n",
        "                img_array = cv2.imread(os.path.join(path,img)) # convert to array\n",
        "                if (img_array is None):\n",
        "                    print(\"\\n\",os.path.join(path,img),\" is not an image file...not added to the datasets\\n\")\n",
        "                    continue\n",
        "                dataset.append(img_array)  # add this to our cancer_data\n",
        "                             \n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "            \n",
        "  return dataset , filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e_86Vn6PDh4"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q5KxeCPMUoO"
      },
      "source": [
        "#train - loaded augmented image dataset\n",
        "#train_filenames - Files names of all train images\n",
        "train , train_filenames = create_dataset(AUGMENTED_TRAIN_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umKbZfrjZsLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7acda3e-bf89-49f7-ac29-510749dad83d"
      },
      "source": [
        "#sample_file_names\n",
        "train_filenames[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cancer_64_113161.png',\n",
              " 'cancer_7_9000135.png',\n",
              " 'cancer_68_3965186.png',\n",
              " 'cancer_92_5605225.png',\n",
              " 'cancer_65_3927776.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQG7wwEZPNVf"
      },
      "source": [
        "Verify number of train images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZphRNHOJO8Jm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9143372-a823-4450-cb60-ecd16525b270"
      },
      "source": [
        "print(len(train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpQIwf60PRkc"
      },
      "source": [
        "Create Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUtA1chOge9"
      },
      "source": [
        "test , test_filenames = create_dataset(ORIGINAL_TEST_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uvZPU0dPVeT"
      },
      "source": [
        "Verify number of test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEOB7cKYNzM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a11124f-1a8f-4888-b487-79fd2cc350a5"
      },
      "source": [
        "print(len(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbES8p92HX36"
      },
      "source": [
        "### Create mask\n",
        "\n",
        "Create label dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ldgwnwWikFB"
      },
      "source": [
        "#Create mask for given image\n",
        "def create_mask(img_array):\n",
        "\n",
        "  blurred_frame=cv2.GaussianBlur(img_array, (5, 5), 0)\n",
        "\n",
        "  # Convert blurred frame from BGR to HSV\n",
        "  hsv=cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  # Set the lower and upper bound of HSV.\n",
        "  # Lower bound = (Lower hue,lower saturation,lower value)\n",
        "  # Upper bound = (upper hue,upper saturation,upper value)\n",
        "  l_b=np.array([58, 132, 186])\n",
        "  u_b=np.array([255, 255, 255])\n",
        "\n",
        "  # Set the mask range of lower and upper HSV bounds\n",
        "  mask=cv2.inRange(hsv, l_b, u_b)\n",
        "\n",
        "  kernel=np.ones((5, 5), np.uint8)\n",
        "\n",
        "  #Morphological transformation:\n",
        "  #Operation:Opening - Erosion followed by dilation. Useful for removing noise\n",
        "  #Erosion - It is useful for removing small white noises based on kernel size.It also shrinks the mask area.\n",
        "  #Dilation - Increase area of the mask after erosion.\n",
        "  mask=cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "  #Converts every pixel to white or black based on the given threshold. It also smoothens the edges\n",
        "  #Otsu's Binarization - Otsu's method avoids having to choose a threshold value and determines it automatically. - https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html\n",
        "  ret, thresh=cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "  return thresh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxqYxWJBHaww"
      },
      "source": [
        "### Create mask ground truth images Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Zp4hoJXpAZ"
      },
      "source": [
        "#Return masked images\n",
        "def create_mask_dataset(dataset ):\n",
        "  mask_dataset = []\n",
        "  for img_array in dataset:\n",
        "            mask_dataset.append(create_mask(img_array))\n",
        "  return mask_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdD-gMXMZEKp"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdxcXE7LYckZ"
      },
      "source": [
        "#Create mask dataset from the loaded train images\n",
        "train_mask = create_mask_dataset(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8wlnPkm1oKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5759a4e6-c1ea-4a30-84b0-f3dd467d09ee"
      },
      "source": [
        "len(train_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV7bPO5EZI0t"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5TtVvHvY3L_"
      },
      "source": [
        "#Mask for test dataset\n",
        "test_mask = create_mask_dataset(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC0Bm0i_6I3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2971ac-b8c6-45ca-867c-36b38599d74b"
      },
      "source": [
        "len(test_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4drfQZSIMPV"
      },
      "source": [
        "### Save mask datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pnUUIYJaJI0"
      },
      "source": [
        "#Saves the masks created in google drive\n",
        "#File names ensure both train image and its corresponding mask have same filename.This will be required to create segmentation dataset\n",
        "def save_dateset(mask_dataset , filenames , path):\n",
        "  delete_folder_contents(path)\n",
        "  for i,img in enumerate(mask_dataset):\n",
        "    cv2.imwrite(os.path.join(path ,filenames[i]), img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMLexStffuxJ"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO0RkBslawsS"
      },
      "source": [
        "#Save train masks\n",
        "save_dateset(train_mask ,train_filenames, MASK_TRAIN_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vVgtNIBfxM5"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpJZHnrgfnug"
      },
      "source": [
        "#Save test masks\n",
        "save_dateset(test_mask ,test_filenames, MASK_TEST_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}